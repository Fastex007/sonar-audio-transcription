import os
import logging
import torch
import whisper
from pyannote.audio import Pipeline
import warnings
from tqdm import tqdm

warnings.filterwarnings("ignore")

logger = logging.getLogger(__name__)


class MLProcessor:
    def _setup_devices(self):
        logger.info("üîß –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏...")
        logger.info(f"   CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.is_available()}")
        logger.info(f"   MPS –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.backends.mps.is_available()}")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –∑–∞–ø—É—â–µ–Ω—ã –ª–∏ –º—ã –≤ Docker (MPS –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç –≤ Docker –Ω–∞ Mac)
        is_docker = os.path.exists('/.dockerenv') or os.environ.get('CUDA_VISIBLE_DEVICES') == ''
        if is_docker:
            logger.info("üê≥ –û–±–Ω–∞—Ä—É–∂–µ–Ω Docker - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ CPU")

        # –í–ê–ñ–ù–û: –ù–∞ M1/M2 Mac Whisper —Ä–∞–±–æ—Ç–∞–µ—Ç —Å—Ç–∞–±–∏–ª—å–Ω–µ–µ –Ω–∞ CPU
        # –∏–∑-–∑–∞ –ø—Ä–æ–±–ª–µ–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å MPS –Ω–∞ ARM64
        self.whisper_device = "cpu"

        # –î–ª—è diarization –ø—Ä–æ–±—É–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å GPU/MPS –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ
        # –ù–û –Ω–µ –≤ Docker –Ω–∞ Mac (MPS –Ω–µ –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è)
        if torch.cuda.is_available() and not is_docker:
            self.torch_device = "cuda"
            logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º CUDA GPU")
        elif torch.backends.mps.is_available() and not is_docker:
            self.torch_device = "mps"
            logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è Whisper, MPS –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏")
        else:
            self.torch_device = "cpu"
            logger.info("‚úÖ –ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")

        # –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
        self.device = self.whisper_device

        logger.info(f"üì± Whisper device: {self.whisper_device.upper()}")
        logger.info(f"üì± Torch device: {self.torch_device.upper()}")

    def __init__(self):
        logger.info("=" * 70)
        logger.info("üöÄ Initializing ML Processor...")
        logger.info("=" * 70)

        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤
        self._setup_devices()

        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–∏
        cache_dir = os.path.expanduser("~/.cache")
        whisper_cache = os.path.join(cache_dir, "whisper")
        torch_cache = os.path.join(cache_dir, "torch")

        whisper_cached = os.path.exists(os.path.join(whisper_cache, "base.pt"))
        logger.info(f"üì¶ Whisper cache: {'‚úÖ Found' if whisper_cached else '‚è¨ Will download (~150MB)'}")
        logger.info(f"üìÇ Cache location: {whisper_cache}")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º Whisper –º–æ–¥–µ–ª—å (base –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ ARM64)
        logger.info("")
        logger.info("=" * 70)
        logger.info("üé§ Loading Whisper model (base)...")
        logger.info("=" * 70)

        if not whisper_cached:
            logger.info("‚è¨ Downloading Whisper model... (~150MB)")
            logger.info("üí° Tip: Model will be cached for future use")

        self.whisper_model = whisper.load_model("base", device=self.device)
        logger.info("‚úÖ Whisper model loaded successfully")

        # –ó–∞–≥—Ä—É–∂–∞–µ–º pyannote –º–æ–¥–µ–ª—å –¥–ª—è –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–∏
        logger.info("")
        logger.info("=" * 70)
        logger.info("üë• Loading pyannote diarization model...")
        logger.info("=" * 70)

        try:
            # –ü–æ–ª—É—á–∞–µ–º —Ç–æ–∫–µ–Ω HuggingFace
            hf_token = os.environ.get('HF_TOKEN', None)
            logger.info(f"üîë HuggingFace token: {'‚úÖ Found' if hf_token else '‚ùå Not set'}")

            if not hf_token:
                logger.error("HUGGINGFACE_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω! –î–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å")
                logger.error("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ —Ç–æ–∫–µ–Ω: export HF_TOKEN=hf_your_token")
                self.diarization_pipeline = None
                logger.warning("‚ö†Ô∏è  Diarization –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–∑-–∑–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Ç–æ–∫–µ–Ω–∞")
            elif not hf_token.startswith('hf_'):
                logger.error(f"–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–æ–∫–µ–Ω–∞ HuggingFace: {hf_token[:10]}...")
                logger.error("–¢–æ–∫–µ–Ω –¥–æ–ª–∂–µ–Ω –Ω–∞—á–∏–Ω–∞—Ç—å—Å—è —Å 'hf_'")
                self.diarization_pipeline = None
                logger.warning("‚ö†Ô∏è  Diarization –æ—Ç–∫–ª—é—á–µ–Ω–∞ –∏–∑-–∑–∞ –Ω–µ–≤–µ—Ä–Ω–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ —Ç–æ–∫–µ–Ω–∞")
            else:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
                logger.info("‚è¨ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ pyannote/speaker-diarization-3.1...")
                try:
                    self.diarization_pipeline = Pipeline.from_pretrained(
                        "pyannote/speaker-diarization-3.1",
                        use_auth_token=hf_token
                    )
                    logger.info("‚úÖ –ú–æ–¥–µ–ª—å pyannote —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                except Exception as download_error:
                    logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏ 3.1: {download_error}")
                    logger.info("–ü—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å pyannote/speaker-diarization...")
                    try:
                        self.diarization_pipeline = Pipeline.from_pretrained(
                            "pyannote/speaker-diarization",
                            use_auth_token=hf_token
                        )
                        logger.info("‚úÖ –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                    except Exception as alt_error:
                        logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ–π –º–æ–¥–µ–ª–∏: {alt_error}")
                        raise download_error

                # –ö–†–ò–¢–ò–ß–ù–û: –ü–µ—Ä–µ–Ω–æ—Å–∏–º pipeline –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ —Å fallback
                if self.torch_device != "cpu":
                    try:
                        logger.info(f"–ü–µ—Ä–µ–Ω–æ—Å–∏–º diarization –Ω–∞ {self.torch_device.upper()}...")
                        self.diarization_pipeline = self.diarization_pipeline.to(
                            torch.device(self.torch_device)
                        )
                        logger.info(f"‚úÖ Diarization –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ {self.torch_device.upper()}")
                    except Exception as e:
                        logger.warning(f"‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–µ—Ä–µ–º–µ—Å—Ç–∏—Ç—å –Ω–∞ {self.torch_device}: {e}")
                        logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ–º CPU –≤–º–µ—Å—Ç–æ —ç—Ç–æ–≥–æ...")
                        self.diarization_pipeline = self.diarization_pipeline.to(
                            torch.device("cpu")
                        )
                        logger.info("‚úÖ Diarization –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")
                else:
                    self.diarization_pipeline = self.diarization_pipeline.to(
                        torch.device("cpu")
                    )
                    logger.info("‚úÖ Diarization –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞ CPU")

                logger.info("‚úÖ Diarization –≥–æ—Ç–æ–≤–∞ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é")

        except Exception as e:
            logger.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ pyannote: {e}")
            logger.error(f"–¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
            import traceback
            logger.error(f"–°—Ç–µ–∫ –≤—ã–∑–æ–≤–æ–≤:\n{traceback.format_exc()}")
            logger.warning("‚ö†Ô∏è  Diarization –±—É–¥–µ—Ç –æ—Ç–∫–ª—é—á–µ–Ω–∞")
            self.diarization_pipeline = None

        logger.info("")
        logger.info("=" * 70)
        logger.info("‚ú® ML Processor ready!")
        logger.info("=" * 70)

    def transcribe_audio(self, audio_path, language='ru'):
        logger.info(f"Transcribing audio: {audio_path}")

        try:
            # –†–∞—Å–ø–æ–∑–Ω–∞–µ–º —Ä–µ—á—å
            # fp16=False –∫—Ä–∏—Ç–∏—á–Ω–æ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏ –Ω–∞ ARM64 Mac
            result = self.whisper_model.transcribe(
                audio_path,
                language=language,
                task='transcribe',
                verbose=False,
                word_timestamps=True,  # –ü–æ–ª—É—á–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –¥–ª—è —Å–ª–æ–≤
                fp16=False  # –û—Ç–∫–ª—é—á–∞–µ–º fp16 –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å ARM64
            )

            logger.info("Transcription completed successfully")
            logger.info(f"Detected language: {result['language']}")
            logger.info(f"Text length: {len(result['text'])} chars")
            logger.info(f"Segments: {len(result['segments'])}")

            return result

        except Exception as e:
            logger.error(f"Transcription error: {e}")
            raise

    def diarize_audio(self, audio_path):
        if not self.diarization_pipeline:
            logger.warning("Diarization pipeline not available, skipping")
            return []

        logger.info(f"Diarizing audio: {audio_path}")

        try:
            # –ó–∞–ø—É—Å–∫–∞–µ–º –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—é
            diarization = self.diarization_pipeline(audio_path)

            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Å–ø–∏—Å–æ–∫
            segments = []
            for turn, _, speaker in diarization.itertracks(yield_label=True):
                segments.append({
                    'start': turn.start,
                    'end': turn.end,
                    'speaker': speaker
                })

            logger.info("Diarization completed successfully")
            logger.info(f"Found {len(set(s['speaker'] for s in segments))} speakers")
            logger.info(f"Total segments: {len(segments)}")

            return segments

        except Exception as e:
            logger.error(f"Diarization error: {e}")
            # –ù–µ –ø–∞–¥–∞–µ–º, –ø—Ä–æ—Å—Ç–æ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—É—Å—Ç–æ–π —Å–ø–∏—Å–æ–∫
            return []

    def merge_transcription_and_diarization(self, transcription, diarization):
        logger.info("Merging transcription and diarization...")

        utterances = []

        if not diarization:
            # –ï—Å–ª–∏ –¥–∏–∞—Ä–∏–∑–∞—Ü–∏—è –Ω–µ –ø—Ä–æ—à–ª–∞, –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é
            logger.info("No diarization data, using transcription only")
            for idx, segment in enumerate(transcription['segments']):
                utterances.append({
                    'speaker': 'SPEAKER_00',
                    'text': segment['text'].strip(),
                    'start': segment['start'],
                    'end': segment['end'],
                    'confidence': segment.get('no_speech_prob', 0.0)
                })
            return utterances

        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Å–µ–≥–º–µ–Ω—Ç—ã —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏–∏ —Å –¥–∏–∞—Ä–∏–∑–∞—Ü–∏–µ–π
        for segment in transcription['segments']:
            seg_start = segment['start']
            seg_end = segment['end']
            seg_text = segment['text'].strip()

            # –ù–∞—Ö–æ–¥–∏–º —Å–ø–∏–∫–µ—Ä–∞ –¥–ª—è —ç—Ç–æ–≥–æ —Å–µ–≥–º–µ–Ω—Ç–∞
            # –ë–µ—Ä–µ–º —Å–ø–∏–∫–µ—Ä–∞ —Å –Ω–∞–∏–±–æ–ª—å—à–∏–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ–º
            best_speaker = 'SPEAKER_00'
            max_overlap = 0

            for dia_seg in diarization:
                # –í—ã—á–∏—Å–ª—è–µ–º –ø–µ—Ä–µ–∫—Ä—ã—Ç–∏–µ
                overlap_start = max(seg_start, dia_seg['start'])
                overlap_end = min(seg_end, dia_seg['end'])
                overlap = max(0, overlap_end - overlap_start)

                if overlap > max_overlap:
                    max_overlap = overlap
                    best_speaker = dia_seg['speaker']

            utterances.append({
                'speaker': best_speaker,
                'text': seg_text,
                'start': seg_start,
                'end': seg_end,
                'confidence': 1.0 - segment.get('no_speech_prob', 0.0)
            })

        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω—ã–µ utterances –æ–¥–Ω–æ–≥–æ —Å–ø–∏–∫–µ—Ä–∞
        merged_utterances = []
        current = None

        for utt in utterances:
            if current is None:
                current = utt.copy()
            elif current['speaker'] == utt['speaker'] and (utt['start'] - current['end']) < 1.0:
                # –¢–æ—Ç –∂–µ —Å–ø–∏–∫–µ—Ä –∏ –ø–µ—Ä–µ—Ä—ã–≤ < 1 —Å–µ–∫ - –æ–±—ä–µ–¥–∏–Ω—è–µ–º
                current['text'] += ' ' + utt['text']
                current['end'] = utt['end']
                current['confidence'] = (current['confidence'] + utt['confidence']) / 2
            else:
                # –ù–æ–≤—ã–π —Å–ø–∏–∫–µ—Ä –∏–ª–∏ –±–æ–ª—å—à–æ–π –ø–µ—Ä–µ—Ä—ã–≤ - —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏ –Ω–∞—á–∏–Ω–∞–µ–º –Ω–æ–≤—ã–π
                merged_utterances.append(current)
                current = utt.copy()

        if current:
            merged_utterances.append(current)

        logger.info(f"Merged {len(merged_utterances)} utterances successfully")

        return merged_utterances


# Singleton instance - –º–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –ø—Ä–∏ –∏–º–ø–æ—Ä—Ç–µ
_ml_processor = None


def get_ml_processor():
    global _ml_processor
    if _ml_processor is None:
        _ml_processor = MLProcessor()
    return _ml_processor